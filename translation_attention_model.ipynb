{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from os.path import join as pjoin\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import spacy\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "SEED = 111\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listDir(mypath):\n",
    "    onlyfiles = [pjoin(mypath, f) for f in os.listdir(mypath)]\n",
    "    return onlyfiles\n",
    "file_list = listDir(\"korean_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>원문</th>\n",
       "      <th>번역문</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 ...</td>\n",
       "      <td>Bible Coloring' is a coloring application that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>씨티은행에서 일하세요?</td>\n",
       "      <td>Do you work at a City bank?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.</td>\n",
       "      <td>PURITO's bestseller, which recorded 4th rough ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.</td>\n",
       "      <td>In Chapter 11 Jesus called Lazarus from the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.</td>\n",
       "      <td>I would feel grateful to know how many stocks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>나는 먼저 청소기로 바닥을 밀었어요.</td>\n",
       "      <td>First of all, I vacuumed the floor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>나는 먼저 팀 과제를 하고 놀러 갔어요.</td>\n",
       "      <td>I did the team assignment first and went out t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>나는 비 같은 멋진 연예인을 좋아해요.</td>\n",
       "      <td>I like cool entertainer like Rain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>나는 멋진 자연 경치를 보고 눈물을 흘렸어.</td>\n",
       "      <td>I cried seeing the amazing scenery.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200000</th>\n",
       "      <td>나는 멋진 중학교 생활을 기대합니다.</td>\n",
       "      <td>I look forward to a great middle school experi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       원문  \\\n",
       "SID                                                         \n",
       "1       'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 ...   \n",
       "2                                            씨티은행에서 일하세요?   \n",
       "3                   푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.   \n",
       "4        11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.   \n",
       "5          6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.   \n",
       "...                                                   ...   \n",
       "199996                               나는 먼저 청소기로 바닥을 밀었어요.   \n",
       "199997                             나는 먼저 팀 과제를 하고 놀러 갔어요.   \n",
       "199998                              나는 비 같은 멋진 연예인을 좋아해요.   \n",
       "199999                           나는 멋진 자연 경치를 보고 눈물을 흘렸어.   \n",
       "200000                               나는 멋진 중학교 생활을 기대합니다.   \n",
       "\n",
       "                                                      번역문  \n",
       "SID                                                        \n",
       "1       Bible Coloring' is a coloring application that...  \n",
       "2                             Do you work at a City bank?  \n",
       "3       PURITO's bestseller, which recorded 4th rough ...  \n",
       "4       In Chapter 11 Jesus called Lazarus from the to...  \n",
       "5       I would feel grateful to know how many stocks ...  \n",
       "...                                                   ...  \n",
       "199996                First of all, I vacuumed the floor.  \n",
       "199997  I did the team assignment first and went out t...  \n",
       "199998                 I like cool entertainer like Rain.  \n",
       "199999                I cried seeing the amazing scenery.  \n",
       "200000  I look forward to a great middle school experi...  \n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kor_en = pd.read_excel(file_list[0],\n",
    "                          index_col=\"SID\")\n",
    "df_kor_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [03:07<00:00, 1068.10it/s]\n"
     ]
    }
   ],
   "source": [
    "ko_sequences = []\n",
    "en_sequences = []\n",
    "\n",
    "for idx, row in tqdm(df_kor_en.iterrows(), total=200000):\n",
    "    kor, en = row[\"원문\"], row[\"번역문\"]\n",
    "    cleaned_kor = re.sub('[\\.\\?\\!\\,]+','', kor)\n",
    "    cleaned_en = re.sub('[\\.\\?\\!\\,]+','', en)\n",
    "    ko_sequences.append(okt.morphs(cleaned_kor))\n",
    "    en_sequences.append(cleaned_en.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationData(Dataset):\n",
    "    \n",
    "    def __init__(self, from_sentences, to_sentences):\n",
    "        self.init_token = \"<sos>\"\n",
    "        self.end_token = \"<eos>\"\n",
    "        self.end_token_pivot = 2\n",
    "        self.from_sequences, self.from_word_dict = self.tokenize(from_sentences)\n",
    "        self.to_sequences, self.to_word_dict = self.tokenize(to_sentences)\n",
    "        \n",
    "        self.source_dim = len(self.from_word_dict)\n",
    "        self.target_dim = len(self.to_word_dict)\n",
    "    \n",
    "    def _dict_reverse(self, dictionary, value):\n",
    "        for k, v in dictionary.items():\n",
    "            if v == value:\n",
    "                return k\n",
    "        raise KeyError\n",
    "        \n",
    "    def tokenize(self, sentences):\n",
    "        word_dict = {\n",
    "            init_token: 1,\n",
    "            end_token: 2,\n",
    "        }\n",
    "        word_counter = {\n",
    "            1: len(sentences),\n",
    "            2: len(sentences)\n",
    "        }\n",
    "        pivot = 3\n",
    "        sequences = []\n",
    "        for words in sentences:\n",
    "            for word in words:\n",
    "                if word not in word_dict:\n",
    "                    word_dict[word] = pivot\n",
    "                    word_counter[pivot] = 1\n",
    "                    pivot = pivot + 1\n",
    "                else:\n",
    "                    word_counter[word_dict[word]] += 1\n",
    "        \n",
    "        for pivot, count in word_counter.items():\n",
    "            if count == 1:\n",
    "                word = self._dict_reverse(word_dict, pivot)\n",
    "                word_dict[word] = 0\n",
    "        \n",
    "        start_pivot = 3\n",
    "        for key in word_dict.keys():\n",
    "            if word_dict[key] > 2:\n",
    "                word_dict[key] = start_pivot\n",
    "                start_pivot += 1\n",
    "        \n",
    "        for words in sentences:\n",
    "            words = [self.init_token] + words + [self.end_token]\n",
    "            tokens = [word_dict[w] for w in words]\n",
    "            sequences.append(tokens)\n",
    "        \n",
    "        max_len = max(map(len, sequences))\n",
    "        \n",
    "        word_dict = {v: k for k, v in word_dict.items() if v > 0}\n",
    "        word_dict[0] = \"<NONE>\"\n",
    "        print(\"MAX LEN : {}\".format(max_len))\n",
    "        print(\"TOTAL SEQ: {}\".format(len(sequences)))\n",
    "        print(\"WORD DICT LEN: {}\".format(len(word_dict)))\n",
    "        for sequence in sequences:\n",
    "            seq_len = len(sequence)\n",
    "            sequence.extend([self.end_token_pivot] * (max_len - seq_len))\n",
    "        return torch.tensor(sequences), word_dict\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.from_sequences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.from_sequences[index], self.to_sequences[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        \"\"\"\n",
    "        :param input_dim: the size of the one-hot vectors that will be input\n",
    "        :param emb_dim: the dimensionality of the embedding layer\n",
    "        :param enc_hid_dim: the dimensionality of the encoder hidden states\n",
    "        :param dec_hid_dim: the dimensionality of the decoder hidden states\n",
    "        :param dropout: amount of dropout to use\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(enc_hid_dim * 2 + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        :param hidden: [batch size, dec hid dim]\n",
    "        :param encoder_outputs: [src len, batch size, enc hid dim*2]\n",
    "        merge hidden states of decoder and bidrectional output of encoder\n",
    "        \"\"\"\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim,\n",
    "                 dropout, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim + enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.fc_out = nn.Linear(emb_dim + 2 * enc_hid_dim + dec_hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, ipt, hidden, encoder_outputs):\n",
    "        ipt = ipt.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(ipt))\n",
    "        attn = self.attention(hidden, encoder_outputs)\n",
    "        attn = attn.unsqueeze(1)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        weighted = torch.bmm(attn, encoder_outputs)\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        assert (output == hidden).all()\n",
    "\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "        \n",
    "        return prediction, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \"\"\"\n",
    "        :param src: shape (src len, batch size)\n",
    "        :param trg: shape (trg len, batch size)\n",
    "        :param teacher_forcing_ratio: probability to use teacher forcing\n",
    "        \"\"\"\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        ipt = trg[0, :]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "\n",
    "            output, hidden = self.decoder(ipt, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            ipt = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "\n",
    "    def __init__(self, from_seq, to_seq,\n",
    "                 enc_emb_dim=128, dec_emb_dim=128,\n",
    "                 enc_hid_dim=256, dec_hid_dim=256,\n",
    "                 enc_dropout=0.3, dec_dropout=0.3,\n",
    "                 epochs=15):\n",
    "        #self.data = Data()\n",
    "        self.data = TranslationData(from_seq, to_seq)\n",
    "        data_len = len(self.data)\n",
    "        train_num = int(data_len * 0.8)\n",
    "        valid_num = int(data_len * 0.1)\n",
    "        test_num = data_len - train_num - valid_num\n",
    "        train, valid, test = random_split(self.data, [train_num, valid_num, test_num])\n",
    "        self.train_iter = DataLoader(train, batch_size = 256, shuffle=True)\n",
    "        self.valid_iter = DataLoader(valid, batch_size = 256, shuffle=False)\n",
    "        self.test_iter = DataLoader(test, batch_size = 256, shuffle=False)\n",
    "        self.input_dim = self.data.source_dim\n",
    "        self.output_dim = self.data.target_dim\n",
    "\n",
    "        self.enc_emb_dim = enc_emb_dim\n",
    "        self.dec_emb_dim = dec_emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.enc_dropout = enc_dropout\n",
    "        self.dec_dropout = dec_dropout\n",
    "\n",
    "        self.encoder = Encoder(self.input_dim,\n",
    "                               self.enc_emb_dim,\n",
    "                               self.enc_hid_dim,\n",
    "                               self.dec_hid_dim,\n",
    "                               self.enc_dropout)\n",
    "        self.attention = Attention(self.enc_hid_dim, self.dec_hid_dim)\n",
    "        self.decoder = Decoder(self.output_dim,\n",
    "                               self.dec_emb_dim,\n",
    "                               self.enc_hid_dim,\n",
    "                               self.dec_hid_dim,\n",
    "                               self.dec_dropout,\n",
    "                               self.attention)\n",
    "        self.model = Seq2Seq(self.encoder, self.decoder, device).to(device)\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index = self.data.end_token_pivot)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "            else:\n",
    "                nn.init.constant_(param.data, 0)\n",
    "\n",
    "    def count_parameters(self, model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    def train(self, epoch, iterator, optimizer, criterion, clip):\n",
    "        self.model.train()\n",
    "        epoch_loss = 0\n",
    "        pbar = tqdm(enumerate(iterator), total=len(iterator),\n",
    "                    desc=\"({0:^3})\".format(epoch))\n",
    "        for i, batch in pbar:\n",
    "            src = batch[0].transpose_(0, 1).to(device)\n",
    "            trg = batch[1].transpose_(0, 1).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = self.model(src, trg)\n",
    "            # trg = [trg len, batch size]\n",
    "            # output = [trg len, batch size, output dim]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].reshape(-1)\n",
    "            #trg = [(trg len -1) * batch size]\n",
    "            #output = [(trg len -1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm(self.model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        return epoch_loss / len(iterator)\n",
    "\n",
    "    def evaluate(self, iterator, criterion):\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(iterator):\n",
    "                src = batch[0].transpose_(0, 1).to(device)\n",
    "                trg = batch[1].transpose_(0, 1).to(device)\n",
    "                #src = batch.src\n",
    "                #trg = batch.trg\n",
    "                output = self.model(src, trg, 0.0)\n",
    "\n",
    "                #trg = [trg len, batch size]\n",
    "                #output = [trg len, batch size, output dim]\n",
    "\n",
    "                output_dim = output.shape[-1]\n",
    "                output = output[1:].view(-1, output_dim)\n",
    "                trg = trg[1:].reshape(-1)\n",
    "                loss = criterion(output, trg)\n",
    "                epoch_loss += loss.item()\n",
    "        return epoch_loss / len(iterator)\n",
    "\n",
    "    def _epoch_time(self, start_time, end_time):\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_mins = int(elapsed_time / 60)\n",
    "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "        return elapsed_mins, elapsed_secs\n",
    "\n",
    "    def test(self):\n",
    "        self.model.load_state_dict(torch.load(pjoin('model', 'attention.pt')))\n",
    "        test_loss = self.evaluate(self.test_iter, self.criterion)\n",
    "        print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')\n",
    "\n",
    "    def run(self):\n",
    "        self.model.apply(self.init_weights)\n",
    "        print(self.model)\n",
    "        print(\"Model trainable parametes: {}\".format(self.count_parameters(self.model)))\n",
    "\n",
    "        optimizer = optim.Adam(self.model.parameters())\n",
    "\n",
    "        CLIP = 1\n",
    "        best_valid_loss = float('inf')\n",
    "        for epoch in range(self.epochs):\n",
    "            start_time = time.time()\n",
    "            train_loss = self.train(epoch, self.train_iter, optimizer, self.criterion, CLIP)\n",
    "            valid_loss = self.evaluate(self.valid_iter, self.criterion)\n",
    "            end_time = time.time()\n",
    "\n",
    "            epoch_mins, epoch_secs = self._epoch_time(start_time, end_time)\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                torch.save(self.model.state_dict(), pjoin('model', 'attention.pt'))\n",
    "            print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "            print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX LEN : 46\n",
      "TOTAL SEQ: 200000\n",
      "WORD DICT LEN: 38122\n",
      "MAX LEN : 49\n",
      "TOTAL SEQ: 200000\n",
      "WORD DICT LEN: 25440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 0 ):   0%|          | 0/625 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(38122, 128)\n",
      "    (rnn): GRU(128, 256, bidirectional=True)\n",
      "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (attention): Attention(\n",
      "      (attn): Linear(in_features=768, out_features=256, bias=True)\n",
      "      (v): Linear(in_features=256, out_features=1, bias=False)\n",
      "    )\n",
      "    (embedding): Embedding(25440, 128)\n",
      "    (rnn): GRU(640, 256)\n",
      "    (fc_out): Linear(in_features=896, out_features=25440, bias=True)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      ")\n",
      "Model trainable parametes: 32566624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soon/anaconda3/envs/nlptorch/lib/python3.7/site-packages/ipykernel_launcher.py:78: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "\n",
      "( 0 ):   0%|          | 1/625 [00:18<3:07:57, 18.07s/it]\u001b[A\n",
      "( 0 ):   0%|          | 2/625 [00:37<3:13:16, 18.61s/it]\u001b[A\n",
      "( 0 ):   0%|          | 3/625 [00:55<3:08:40, 18.20s/it]\u001b[A\n",
      "( 0 ):   1%|          | 4/625 [01:14<3:11:59, 18.55s/it]\u001b[A\n",
      "( 0 ):   2%|▏         | 12/625 [03:36<3:09:34, 18.56s/it]\u001b[A\n",
      "( 0 ):   2%|▏         | 13/625 [03:54<3:07:57, 18.43s/it]\u001b[A\n",
      "( 0 ):   2%|▏         | 14/625 [04:12<3:04:50, 18.15s/it]\u001b[A\n",
      "( 0 ):   2%|▏         | 15/625 [04:29<3:01:15, 17.83s/it]\u001b[A\n",
      "( 0 ):   3%|▎         | 16/625 [04:46<2:59:02, 17.64s/it]\u001b[A\n",
      "( 0 ):   3%|▎         | 17/625 [05:06<3:04:02, 18.16s/it]\u001b[A\n",
      "( 0 ):   3%|▎         | 18/625 [05:23<3:00:36, 17.85s/it]\u001b[A\n",
      "( 0 ):   3%|▎         | 19/625 [05:40<2:57:50, 17.61s/it]\u001b[A\n",
      "( 0 ):   3%|▎         | 20/625 [05:57<2:57:24, 17.59s/it]\u001b[A\n",
      "( 0 ):   3%|▎         | 21/625 [06:14<2:55:40, 17.45s/it]\u001b[A\n",
      "( 0 ):   4%|▎         | 22/625 [06:32<2:56:26, 17.56s/it]\u001b[A\n",
      "( 0 ):   4%|▎         | 23/625 [06:49<2:55:02, 17.45s/it]\u001b[A\n",
      "( 0 ):   4%|▍         | 24/625 [07:07<2:54:08, 17.38s/it]\u001b[A\n",
      "( 0 ):   4%|▍         | 25/625 [07:24<2:52:45, 17.28s/it]\u001b[A\n",
      "( 0 ):   4%|▍         | 26/625 [07:41<2:51:58, 17.23s/it]\u001b[A\n",
      "( 0 ):   4%|▍         | 27/625 [07:58<2:52:27, 17.30s/it]\u001b[A\n",
      "( 0 ):   4%|▍         | 28/625 [08:16<2:52:22, 17.32s/it]\u001b[A\n",
      "( 0 ):   5%|▍         | 29/625 [08:36<3:00:09, 18.14s/it]\u001b[A\n",
      "( 0 ):   5%|▍         | 30/625 [08:53<2:57:34, 17.91s/it]\u001b[A\n",
      "( 0 ):   5%|▍         | 31/625 [09:10<2:54:56, 17.67s/it]\u001b[A\n",
      "( 0 ):   5%|▌         | 32/625 [09:30<3:00:12, 18.23s/it]\u001b[A\n",
      "( 0 ):   5%|▌         | 33/625 [09:48<3:01:04, 18.35s/it]\u001b[A\n",
      "( 0 ):   5%|▌         | 34/625 [10:06<2:59:02, 18.18s/it]\u001b[A\n",
      "( 0 ):   6%|▌         | 35/625 [10:23<2:56:15, 17.92s/it]\u001b[A\n",
      "( 0 ):   6%|▌         | 36/625 [10:42<2:57:23, 18.07s/it]\u001b[A\n",
      "( 0 ):   6%|▌         | 37/625 [10:59<2:55:48, 17.94s/it]\u001b[A\n",
      "( 0 ):   6%|▌         | 38/625 [11:17<2:54:05, 17.79s/it]\u001b[A\n",
      "( 0 ):   6%|▌         | 39/625 [11:34<2:52:04, 17.62s/it]\u001b[A\n",
      "( 0 ):   6%|▋         | 40/625 [11:52<2:52:06, 17.65s/it]\u001b[A\n",
      "( 0 ):   7%|▋         | 41/625 [12:09<2:49:08, 17.38s/it]\u001b[A\n",
      "( 0 ):   7%|▋         | 42/625 [12:26<2:48:26, 17.34s/it]\u001b[A\n",
      "( 0 ):   7%|▋         | 43/625 [12:45<2:52:15, 17.76s/it]\u001b[A\n",
      "( 0 ):   7%|▋         | 44/625 [13:04<2:56:54, 18.27s/it]\u001b[A\n",
      "( 0 ):   7%|▋         | 45/625 [13:21<2:53:29, 17.95s/it]\u001b[A\n",
      "( 0 ):   7%|▋         | 46/625 [13:42<3:00:01, 18.66s/it]\u001b[A\n",
      "( 0 ):   8%|▊         | 47/625 [14:01<3:01:00, 18.79s/it]\u001b[A\n",
      "( 0 ):   8%|▊         | 48/625 [14:18<2:56:37, 18.37s/it]\u001b[A\n",
      "( 0 ):   8%|▊         | 49/625 [14:35<2:52:42, 17.99s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "train = Train(ko_sequences, en_sequences)\n",
    "train.run()\n",
    "train.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlptorch",
   "language": "python",
   "name": "nlptorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
